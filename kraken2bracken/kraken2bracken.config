params {
    // Input options
    kraken2_db = null
    kraken2_threads = 4
    bracken_threads = 10
    memory_mapping = false
    kmer_len = 35  // default provided bracken2 
    read_len = null  // ideal length of reads in sample
    bracken_classification_level = 'S'  // [Options = 'D','P','C','O','F','G','S'] - taxonomic rank to analyze for bracken2
    threshold = 10  // minimum number of reads required for a classification at the specified rank
    get_classified_reads = false
    enable_building = false
}

process {
    withName:KRAKEN2 {
        cpus = { params.kraken2_threads }
        memory = { (params.memory_mapping == true ? "1.GB" : estimate_kraken_mem(params.kraken2_db, 1, task)) }
        if (params.memory_mapping == true){
            scratch = true
        }
    }
    withName:SEARCH_LIBRARY {
        cpus = { params.bracken_threads }
        memory = { estimate_kraken_mem(params.kraken2_db, 120, task) } // probably need to add ~120GB to kraken2 db size! Used 245.729GB mem for Kraken2 db with hash.k2d = 132G).
    }
    withName:KMER2READ_DIST {
        cpus = { params.bracken_threads }
        memory = { estimate_kraken_mem(params.kraken2_db, 120, task) } // probably need to add ~120GB to kraken2 db size! Used 245.729GB mem for Kraken2 db with hash.k2d = 132G).
    }
}

def estimate_kraken_mem(db, top_up, task) {
    float attempt = task.attempt
    float top_up_float = top_up 
    def file_size = new File("${db}/hash.k2d").size()
    def space_top_up = (top_up_float * 1024**3) * attempt
    def space_to_request_bytes = (file_size * chunkfraction) + space_top_up
    def space_to_request_mb = space_to_request_bytes / (1024**2)
    def valid_space = "${space_to_request_mb.round()}.MB"
    if (valid_space.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1) {
        return params.max_memory as nextflow.util.MemoryUnit
    }
    else {
        return valid_space
    }
}