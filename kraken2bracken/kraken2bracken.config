params {
    // Input options
    kraken2_db = null
    kraken2_threads = 4
    bracken_threads = 10
    kmer_len = 35  // default provided bracken2 
    read_len = null  // ideal length of reads in sample
    classification_level = 'S'  // [Options = 'D','P','C','O','F','G','S'] - taxonomic rank to analyze for bracken2
    threshold = 10  // minimum number of reads required for a classification at the specified rank
    get_classified_reads = false
}

process {
    withName:KRAKEN2 {
        cpus = { params.kraken2_threads }
        memory = { estimate_kraken_mem(params.kraken2_db, 1, task) }
    }
    withName:SEARCH_LIBRARY {
        cpus = { params.bracken_threads }
        memory = { estimate_kraken_mem(params.kraken2_db, 120, task) } // probably need to add ~120GB to kraken2 db size! Used 245.729GB mem for Kraken2 db with hash.k2d = 132G).
    }
    withName:KMER2READ_DIST {
        cpus = { params.bracken_threads }
        memory = { estimate_kraken_mem(params.kraken2_db, 120, task) } // probably need to add ~120GB to kraken2 db size! Used 245.729GB mem for Kraken2 db with hash.k2d = 132G).
    }
}

/*
Estimates required memory from kraken2 database files, accepts a memory top_up (in GB) to provide head room.
top_up will be increased linearly with each task attempt up to params.max_memory
*/
def estimate_kraken_mem(db, top_up, task) {
    float attempt = task.attempt
    float top_up_float = top_up
    def mem_file = new File("${db}/hash.k2d").size()
    def mem_top_up = (top_up_float * 1024**3) * attempt
    def mem_bytes = mem_file + mem_top_up
    def mem_mb = mem_bytes / (1024**2)
    def valid_mem = "${mem_mb.round()}.MB"
    if (valid_mem.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1) {
        return params.max_memory as nextflow.util.MemoryUnit
    }
    return valid_mem
}
