params {
    // Input options
    kraken2_db = null
    kraken2_threads = 4
    bracken_threads = 10
    memory_mapping = false
    kmer_len = 35  // default provided bracken2 
    read_len = null  // ideal length of reads in sample
    bracken_classification_level = 'S'  // [Options = 'D','P','C','O','F','G','S'] - taxonomic rank to analyze for bracken2
    threshold = 10  // minimum number of reads required for a classification at the specified rank
    get_classified_reads = false
    enable_building = false
}

process {
    withName: 'KRAKEN2.*' {
        cpus = { params.kraken2_threads }
        memory = { (params.memory_mapping == true ? "1.GB" : estimate_kraken_mem(params.kraken2_db, 1, task)) }
        if (params.memory_mapping == true){
            scratch = true
            clusterOptions = {
                "-R 'select[tmp>" + estimate_kraken_tmp(params.kraken2_db, 1, task) as String + "]'"
            }
        }
    }
    withName:SEARCH_LIBRARY {
        cpus = { params.bracken_threads }
        memory = { estimate_kraken_mem(params.kraken2_db, 120, task) } // probably need to add ~120GB to kraken2 db size! Used 245.729GB mem for Kraken2 db with hash.k2d = 132G).
    }
    withName:KMER2READ_DIST {
        cpus = { params.bracken_threads }
        memory = { estimate_kraken_mem(params.kraken2_db, 120, task) } // probably need to add ~120GB to kraken2 db size! Used 245.729GB mem for Kraken2 db with hash.k2d = 132G).
    }
}

/*
Estimates required memory/disk space for loading kraken2 database files, with an optional top_up space argument (in GB) to provide head room.
top_up will be increased linearly with each task attempt up to params.max_memory
*/
def estimate_kraken_db_loading_space(db, top_up, task, chunkfraction = 1) {
    float attempt = task.attempt
    float top_up_float = top_up 
    def file_size = new File("${db}/hash.k2d").size()
    def space_top_up = (top_up_float * 1024**3) * attempt
    def space_to_request_bytes = (file_size * chunkfraction) + space_top_up
    def space_to_request_mb = space_to_request_bytes / (1024**2)
    def valid_space = "${space_to_request_mb.round()}.MB"
    return valid_space
}

/*
Wrapper function aimed at estimating memory to request when using Kraken2's default behaviour of loading the entire database into memory. 
This is likely an overestimation of the actual memory required, but provides a safe upper bound for memory requirements when not using memory mapping.
*/
def estimate_kraken_mem(db, top_up, task) {
    valid_space = estimate_kraken_db_loading_space(db, top_up, task)
    if (valid_space.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1) {
        return params.max_memory as nextflow.util.MemoryUnit
    }
    else {
        return valid_space
    }
}

/*
Similar function but aimed to estimate TMP space to request when using Kraken2's memory mapping option and the process scratch directive.
Investigations show that only a chunk of the database is loaded on disk at a time, meaning only a fraction of space equivalent to the size of the hash.k2d file is required. 
*/
def estimate_kraken_tmp(db, top_up, task, chunkfraction = 0.25) {
    return estimate_kraken_db_loading_space(db, top_up, task, chunkfraction)
}