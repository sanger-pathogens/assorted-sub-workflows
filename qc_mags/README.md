# qc_mags

[![Nextflow](https://img.shields.io/badge/nextflow%20DSL2-%E2%89%A521.04.0-23aa62.svg?labelColor=000000)](https://www.nextflow.io/)
[![run with docker](https://img.shields.io/badge/run%20with-docker-0db7ed?labelColor=000000&logo=docker)](https://www.docker.com/)
[![run with singularity](https://img.shields.io/badge/run%20with-singularity-1d355c.svg?labelColor=000000)](https://sylabs.io/docs/)

This workflow performs assembly quality control, with a focus on metagenome-assembled genomes (MAGs).

## Pipeline Summary

It runs the following steps on the assembly (`fasta` files):

1. **gtdbtk classify_wf and QUAST**: Assemblies are classified using steps detailed in the [gtdbtk docs](https://ecogenomics.github.io/GTDBTk/commands/classify_wf.html). The `ani_screen` step is skipped. [QUAST](https://github.com/ablab/quast) evaluates genome/metagenome assemblies by computing various metrics.
2. **checkm2 and GUNC**: [CheckM2](https://github.com/chklovski/CheckM2) is used to predict the completeness and contamination of genomic bins (independent of their taxonomic classification). [GUNC](https://github.com/grp-bork/gunc) is also run to check for chimerism and contamination.
3. **MDMCleaner**: [MDMCleaner](https://github.com/KIT-IBG-5/mdmcleaner) is used to remove contaminants and provide reliable contig classification of metagenome assembled genomes (MAGs). Sequences that are less than 1000 bases long are removed from the resulting filtered/decontaminated fastas using [seqkit](https://bioinf.shenwei.me/seqkit/).
4. **checkm2 and GUNC**: The same checkm2 and GUNC commands (stage 2) are run on the seqkit fasta outputs.
5. **Reporting** A summary CSV report is created that combines the summary files of checkm2, gtdbtk and GUNC runs (both before and after decontamination with MDMCleaner).

### Parameters

Several parameters set paths to various databases used by pipeline tools:

- `--checkm2_db` (default: `/data/pam/software/checkm2_db/uniref100.KO.1.dmnd`)
- `--gunc_db` (default: `/data/pam/software/gunc/GTDB/gunc_db_gtdb95.dmnd`)
- `--mdmcleaner_db` (default: `/data/pam/software/mdmcleaner/v1`)
- `--gtdbtk_db` (default: `/data/pam/software/GTDBTk/release226`)

Other parameters:

- `--fasta_ext` (default: `fa`): Set the expected extension of fasta files in the input directories.
- `--report_config` (default: [`./assets/report_config.json`](./assets/report_config.json)). See [Report configuration](#report-configuration) for more details.
- `--autoqc_config` (default: null) Optional parameter to filter MAGs that pass QC thresholds specified in the config. When applying this option you must either provide the path to a config or with the string "default" use the provided config at `./assorted-sub-workflows/qc_mags/assets/autoqc_config.json`. See [AutoQC configuration](#autoqc-configuration) for more details.
- `--min-contig` (default: 1000 (Note that QUAST will ignore contigs below the set threshold but does not take into account the effects of MDMCleaner))  
- `--skip_raw_reports` (default: false) Skip publishing raw reports from various QC tools, keeping only final summary reports.  
- `--temp_file_storage` (default: `/tmp`): Specify a directory where GTDB-Tk can store temporary files during processing. Options are '/tmp', '/dev/shm' or 'null' (write to memory). See [GTDB-Tk runtime](#gdtbk-runtime) for more details.
- `--temp_space` (default: `30GB`): Request a specific amount of temporary working space to reserve for GTDB-Tk. See [GTDB-Tk runtime](#gdtbk-runtime) for more details.

## Configuration

### Report configuration

A configuration file can be supplied to the `--report_config` option to customise the final (per-sample) report generated by the pipeline. In particular, it allows (per-tool) customization of the identity column (to join the tool report tables together) and extract particular columns from these reports. The following tool names are currently mandatory: `GTDBTK`, `GUNC`, `CHECKM2` (NOTE: tool name must be uppercase). In the following example config block, we select 2 columns (`classification` and `closest_genome_reference`) to extract from the GTDB-Tk report and to use `user_genome` as the identity column:

```
"GTDBTK": {
    "id_column": "user_genome",
    "keep_columns": [
        "classification",
        "closest_genome_reference"
    ]
}
```

Please refer to the default [`report_config.json`](./assets/report_config.json) for expected JSON structure.

NOTE: In addition to columns derived from the tool reports, the script includes 4 columns `preqc_genome_name`, `postqc_genome_name`, `sample_or_strain_name` and `genome_status`. These are currently all derived from filenames (at some point).

| column                | description                                                                              |
| --------------------- | ---------------------------------------------------------------------------------------- |
| preqc_genome_name     | Name of the input fasta file minus extension                                             |
| postqc_genome_name    | Name of the fasta file output after processing with `seqkit` minus extension             |
| sample_or_strain_name | Name of the fasta file up to the last `_` character                                      |
| genome_status         | `mag` if the fasta file contains the string `mag` (lower/uppercase), `isolate` otherwise |

### AutoQC configuration

It is also possible to automatically filter MAGs based on QC metrics produced in the summary report described in [Report configuration](#report-configuration).

To apply this function, you must enable AutoQC by supplying a configuration file path to `--autoqc_config` (config as described [here](../mixed_input/README.md#filter_metadatapy)) or by supplying the string "default" so that the default [autoqc_config.tsv](./assets/autoqc_config.tsv) is used.

The default AutoQC config's pass criteria are:
- Over 90% Completeness
- Under 5% Contamination
- Passes GUNC contamination checks

If writing a custom AutoQC config the filterable columns with the default report config are:
- preqc_genome_name
- postqc_genome_name
- sample_or_strain_name
- genome_status
- checkm2_postqc_Completeness
- checkm2_postqc_Contamination
- checkm2_postqc_Genome_Size
- checkm2_preqc_Completeness
- checkm2_preqc_Contamination
- checkm2_preqc_Genome_Size
- gtdbtk_classification
- gtdbtk_closest_genome_reference
- gunc_postqc_n_contigs
- gunc_postqc_pass.GUNC
- gunc_preqc_n_contigs
- gunc_preqc_pass.GUNC

If using a custom report config you can customise your AutoQC config: for the column using the tool name (lowercase) and keep_column from the report config seperated by an underscore. i.e.  `<tool>_<keep_column>`. Note that for adding filters based on CheckM2 or GUNC you must specify whether to use preqc or postqc reports i.e. `<tool>_<qc_stage>_<keep_column>`, as shown in the filterable column list above.

Please note - if you add the parameter `--autoqc_config` but do not supply either a valid config file path or "default" the pipeline will error on not being able to find a config file to use.

### Inputs

- (Metagenomic) assemblies per sample. Channel emitting elements `[meta, [1.fa, 2.fa, ...]]`, where meta is a map containing metadata (including the mandatory `ID`, tracking a sample ID).

### Outputs

- (Binned) assemblies, each corresponding to a taxonomic unit, that have been decontaminated using MDMCleaner. These decontaminated assemblies are also filtered (sequences less than 1000 bases long are removed). Both sets of assemblies are retained.
- Reports generated by CheckM2, GTDB-Tk, GUNC and QUAST.
- Summary report TSV per-sample (with customisable columns) combining individual reports from various pipeline tools.

### GTDB-Tk runtime

- Runtime and memory can be reduced for GTDB-Tk classficiation by specifying the `--temp_file_storage` option with either `/tmp` or `/dev/shm`. Writing these files to disk instead of keeping everything in memory reduces peak RAM usage by up to 89% and can improve runtime by up to 10%. This often allows the job to run with a smaller memory request, meaning it can start faster on cluster schedulers. 
- If you know the size of your samples you can request a specific temp memory using `--tmp_space <XX>GB`. This lets you reserve a specific amount of temporary memory/disk space. Typically you should request < 100 GB, and no more then 1000 GB, as larger requests may cause jobs to remain pending. Note that due to a know bug reported in the farm documentation, request half the memory you require as LSF double-accounts /tmp use see [here](https://ssg-confluence.internal.sanger.ac.uk/spaces/FARM/pages/101361225/Useful+LSF+resources#UsefulLSFresources-Resources).

### Dependencies

All dependencies are containerised. The [report.py](./bin/report.py) is used for the `REPORTING` process to generate the TSV summary.

### Troubleshooting

If a process in the pipeline fails with a non-zero exit code that is not recognised as a signal that memory or runtime limits were reached, the process will not be re-run and will be ignored. To understand why it has been ignored, please check the process-specific log file `.command.log` in the work directory of the affected process.

On the Sanger farm (HPC), a post-run script is available to automatically show the end of these log files (where informative messages can often be found) and return affected sample identifiers. See [here](https://ssg-confluence.internal.sanger.ac.uk/spaces/PaMI/pages/181078206/General+pipeline+info#Generalpipelineinfo-Usingthepipelinetracefile) for more details.